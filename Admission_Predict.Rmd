---
title: 'PRACTICA 2: LIMPIEZA Y VALIDACIÓN DE LOS DATOS' 
author: "Sabela de La Torre y Gervasio Cuenca" 
tuthor: "Mireia Calvo Gonzalez" 
date: '`r format(Sys.Date(),"%e de %B %Y")`' 
output: 
 html_document: 
   toc: yes 
   number_sections: yes 
   toc_depth: 3 
 pdf_document:
  toc: yes
  toc_depth: 3
  number_sections: yes
---
 
 
```{r setup, include=FALSE} 
 knitr::opts_chunk$set(echo = TRUE) 
``` 
```{r load_libraries, include=FALSE}
if(!require(kableExtra)) {
  install.packages("kableExtra")
  library(kableExtra); 
}
```
\newcommand\pvalue{\mathop{\mbox{$p$-$\mathit{value}$}}}

****
# Descripción del dataset
## ¿Por qué es importante y qué pregunta / problema pretende responder?
****

El dataset escogido describe la probabilidad de ser aceptado en la universidad, en función de una serie de parámetros basados en la actividad escolar de los candidatos. 

El dataset se ha extraído de kaggle, se puede acceder a él desde el siguiente link:
https://www.kaggle.com/mohansacharya/graduate-admissions/downloads/graduate-admissions.zip/2

Con este dataset pretendemos averiguar la probabilidad que tiene un alumno de ser aceptado en la universidad basándonos en sus cualificaciones académicas. Consideramos que puede ser un estudio interesante, ya que puede servir como herramienta para los orientadores escolares para guiar a los alumnos en sus elecciones de estudios superiores.

El dataset consta de 500 registros, correspondientes a 500 alumnos y 9 atributos, a continuación describimos cada uno de estos atributos:

* Serial Nº: Identificador de alumno.
* GRE score: Nota obtenida en el Grade Record Examinations, sería el equivalente a la selectividad española.
* TOEFL Score: Test de inglés como lengua extranjera.
* University rating: Clasificación de la Universidad. (1-5)
* SOP: Declaración de propósito, dónde el candidato explica por qué es un buen candidato para ser admitido en la universidad. (1-5)
* LOR: Carta de recomendación. (1-5)
* CGPA: Cumulative Grade Point Average (1-9)
* Research: Experiencia en investigación (0,1)
* Chance.of.Admit: Confianza del encuestado en ser aceptado. (0-1)
  
****
# Integración y selección de los datos de interés a analizar
****

Los datos se encuentran en formato csv, realizaremos la carga de todos los registros para su posterior tratamiento. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
## Realizamos la carga de los datos
alumnos <- read.csv("Admission_Predict_Ver1.1.csv", header=TRUE)

## Comprobamos los datos cargados y los tipos de variables asignados
str(alumnos)
```

Se puede comprobar que los datos asignados a las variables del nuestro set de datos son los correctos. Por otro lado, revisando los datos, vemos que no necesitaremos la columna de `Serial.no`, ya que no es necesario para nuestro estudio.

```{r echo=TRUE, message=FALSE, warning=FALSE}
##Eliminamos la primera columna
alumnos_estudio <- alumnos[,-1]


##Comprobamos las variables que nos han quedado en el set de de datos y sus tipos
sapply(alumnos_estudio, function(x) class(x))
```

# Limpieza de los datos

## ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionar estos casos?

Primero buscamos si hay valors vacíos:
```{r}
colSums(is.na(alumnos_estudio))
```
y vemos que no tenemos ninguno.

Ahora analizaremos los datos que tenemos en cada una de las variables (rango, media, mediana, mínimo, máximo y cuartiles) mediante la función `summary`:
```{r}
summary(alumnos_estudio)
```
Vemos que el valor 0 solamente lo encontramos en la variable `Research`, cosa que ya sabíamos porque se trata de una variable binaria.

## Identificación y tratamiento de valores extremos

Una herramienta gràfica muy útil para la detección de valores extremos es el diagrama de caja. Este se basa en los valores de los cuartiles. Usaremos la función `boxplot` para dibujar los diagramas para cada una de las variables:

```{r echo=FALSE, out.width="50%"}
boxplot(alumnos_estudio$GRE.Score, main="GRE.Score", col="lightblue")
boxplot(alumnos_estudio$TOEFL.Score, main="TOEFL.Score", col="lightblue")
```

```{r echo=FALSE, out.width="50%"}
boxplot(alumnos_estudio$University.Rating, main="GRE.Score", col="lightblue")
boxplot(alumnos_estudio$SOP, main="TOEFL.Score", col="lightblue")
```

```{r echo=FALSE, out.width="50%"}
boxplot(alumnos_estudio$LOR, main="LOR", col="lightblue")
boxplot(alumnos_estudio$CGPA, main="CGPA", col="lightblue")
```

Vemos que en la variable `LOR` (carta de recomendación) tenemos un único *outlier* correspondiente al valor 1:
```{r}
boxplot.stats(alumnos_estudio$LOR)$out
```

```{r echo=FALSE, out.width="50%"}
boxplot(alumnos_estudio$Research, main="Research", col="lightblue")
boxplot(alumnos_estudio$Chance.of.Admit, main="Chance.of.Admit", col="lightblue")
```
En la variable `Change.of.Admit` encontramos dos *outliers* con valor 0.34:

```{r}
boxplot.stats(alumnos_estudio$Chance.of.Admit)$out
```

Observando el conjunto de datos, vemos que estos valores son completamente aceptables y, por tanto, no son *outliers* reales.

# Análisis de los datos

## Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar)

```{r}
# Agrupación por alumnos con experiencia en investigación
alumnos.investigadores <- alumnos_estudio[alumnos_estudio$Research == 1,]
alumnos.no.investigadores <- alumnos_estudio[alumnos_estudio$Research == 0,]

# Agrupación por tipo de universidad
alumnos.universidades.top <- alumnos_estudio[alumnos_estudio$University.Rating == 5,]
alumnos.universidades.Buenas <- alumnos_estudio[alumnos_estudio$University.Rating == 4,]
alumnos.universidades.Medias <- alumnos_estudio[alumnos_estudio$University.Rating == 3,]
alumnos.universidades.Acepables <- alumnos_estudio[alumnos_estudio$University.Rating == 2,]
alumnos.universidades.Flojas <- alumnos_estudio[alumnos_estudio$University.Rating == 1,]

# Agrupación por alumnos que optan a universidades de calificación baja vs calificación alta
alumnos.universidades.calif.alta <- alumnos_estudio[alumnos_estudio$University.Rating >= 3,]
alumnos.universidades.calif.baja <- alumnos_estudio[alumnos_estudio$University.Rating < 3,]
```
TODO: Añadir más grupos!

## Comprobación de la normalidad y homogeneidad de la varianza

### Comprobación de la normalidad

Comprobamos si los datos siguen una distribución normal mediante la función `shapiro.test`: si $\pvalue \le 0.05$ se rechaza la hipótesis nula y se concluye que los datos **no** siguen una distribución normal.
```{r}
alpha <- 0.05
col.names = colnames(alumnos_estudio)
var.no.normales <- c()
for (i in 1:ncol(alumnos_estudio)) {
  # Aplicamos el test Shapiro-Wilk
  p_val = shapiro.test(alumnos_estudio[,i])$p.value
  if (p_val <= alpha) {
    var.no.normales <- c(var.no.normales, col.names[i]) 
  }
}
cat("Variables que no siguen una distribución normal: ")
cat(var.no.normales, sep=", ") 
```
Por lo tanto, **ninguna** de las varaibles de nuestro conjunto de datos sigue una distribución normal. Ahora bien, por el **teorema del límite central** sabemos que si la muestra es suficientemente grande (n>30), la distribución de la media de cualquier conjunto de datos se parece a una normal. Así pues, podremos aplicar tests paramétricos pese a que nuestros datos no siguen una distribución normal.

### Homogeneidad de la varianza

Estudiaremos la homocedasticidad, o igualdad de varianzas, entre los grupos formados por alumnos con experiencia en investigación frente a los que no: 
```{r}
fligner.test(Chance.of.Admit ~ Research, data = alumnos_estudio)
```
En este test, la hipótesis nula es que las varianzas de los dos grupos son iguales, por tant, dado que $\pvalue > 0.05$, no podemos rechazar la hipótesis nula y **no** podemos afirmar que las varianzas sean significativamente diferentes.

Repetimos el estudio para la clasificación de las universidades:
```{r}
fligner.test(Chance.of.Admit ~ University.Rating, data = alumnos_estudio)
```
Partimos de la misma hipótesis que el caso anterior, en este caso $\pvalue < 0.05$, por lo tento podemos rechazar la hipótesis nula y **podemos afirmar** que las varianzas sean significativamente diferentes.

## Aplicación de pruebas estadísticas 

Dado que nuestro conjunto de datos contiene más de 30 muestras, ya hemos visto que por el **teorema del límite central** podemos aplicar tests paramétricos aunque nuestros datos no sigan una distribución normal pero deberemos comprobar siempre la igualdad de varianzas. De no cumplirse, tendremos que aplicar un test no paramétrico.

### ¿Hay diferencias en la confianza en ser admitidos según la universidad a la que optan los alumnos?

En esta prueba buscaremos si la confianza en ser admitido, `Chance.of.Admit`, es diferente entre los alumnos que optan a universidades calificadas como bajas, es decir, `University.Rating<3`, y la confianza entre los que optan a aquellas calificadas como altas, `University.Rating>=3`.

En este caso, la hipótsis nula, $H_0$, es que la confiança media de ambas poblaciones, $\mu_1$ y $\mu_2$, es igual y la hipótesis alternativa, $H_1$, que $\mu_1\neq\mu_2$ (bilateral), donde $\mu_1$ es la confiança media de los alumnos que optan por una universidad calificada como baja y $\mu_2$ el otro grupo.
$$
\left\{
\begin{array}{ll}
H_{0}: &  \mu_1=\mu_2\\
H_{1}: & \mu_1\neq\mu_2
\end{array}
\right.
$$
Dado que en el apartado anterior hemos visto que la clasificación por universidades no cumple la igualdad de varianzas, debemos aplicar un test no paramétrico como la prueba de Mann-Whitney para datos independientes. Por lo tanto usaremos la función `wilcox.test` para realizar el contraste de hipòtesis usando un valor $\alpha=0.05$:
```{r}
wilcox.test(alumnos.universidades.calif.baja$Chance.of.Admit, alumnos.universidades.calif.alta$Chance.of.Admit, alternative = "two.sided", conf.level=0.05)
```
Podemos ver que $\pvalue=2.2e^{-16} < 0.05$, por tanto, podemos **rechazar** la hipótesis nula y afirmar que haya una diferencia **significativa** en la confianza en ser admitidos entre los dos grupos.

### ¿Qué variables afectan más a la posibilidad de ser admitido en una universidad?
Para intentar contestar a esta pregunta, estudiaremos la correlación entre las diferentes variables de nuetros modelo con la probabilidad de ser admitido. Para ello calcularemos el coeficiente de correlación que mide la asociación entre dos variables. Los posibles valores que puede tomar el coeficiente de correlación varia entre -1 y 1, donde el valor de los extremos indican una correlación perfecta u el 0 indica la ausencia de correlación. EL signo es positivo cuando ambas variables se incrementan o disminuyen simultaneamente, el signo es engativo cuando los valores elevados de una variable se asocian a valores pequeños de otra.

En este caso untilizaremos la correlación de Spearman como test no parámetrico ya que las variables no siguen una distribución normal, aunque sería válido usar la correlación de Pearson, por el **teorema del límite central** citado con anterioridad.

```{r}

alumnos.correlacion <- matrix(nc=2, nr=0)
colnames(alumnos.correlacion) <- c("estimate", "p-value")

## Realizamos el cálculo de la correlación

for (i in 1:(ncol(alumnos_estudio)-1)){
  test = cor.test(alumnos_estudio[,i], alumnos_estudio[,length(alumnos_estudio)], method = "spearman", exact = FALSE )
  estimado = test$estimate 
  p_valor = test$p.value
  
  ##Añadimos el valor a la matriz
  valores = matrix(ncol = 2, nrow = 1)
  valores[1][1] = estimado
  valores[2][1] = p_valor
  alumnos.correlacion <- rbind(alumnos.correlacion, valores)
  rownames(alumnos.correlacion)[nrow(alumnos.correlacion)] <- colnames(alumnos_estudio)[i]  
}

print(alumnos.correlacion)
```
Analizando los resultados vemos que las dos variables que tienen una mayor correlación con la posibilidad de ser admitido son 'CGPA' y 'GRE.Score'. Hemos añadido el p-valor, porque nos puede dar el peso estadístico de la correlación obtenida.

# Representación de los resultados a partir de tablas y gráficas

# Resolución del problema

## A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

# Código

# Contribuciones
```{r echo=FALSE}
participacion <- matrix(
  c(
  "Búsqueda previa",
  "Gervasio Cuenca, Sabela de la Torre",
  "Redacción de las respuestas",
  "Gervasio Cuenca, Sabela de la Torre",
  "Desarrollo código",
  "Gervasio Cuenca, Sabela de la Torre"
  ),
  ncol = 2,
  byrow = TRUE
  )
colnames(participacion) <- c("Contribuciones", "Firma")

knitr::kable(participacion)  %>%
kable_styling("striped", full_width = F)
```
